---
title: 数学随笔3：简述基底思想
date: 2026/1/10
categories: ['数学随笔']
tags: ['数学随笔', '数学']
pinned: 10
---
高中学习向量时，便常听老师说要有基底思想，要学会用一组基表示所有向量。到了学习线代，基底仍然是非常好的化抽象为具象的手段。一个抽象的线性映射往往让人无从下手，设出基底，我们才能看到一个个的可感的对象。通常的处理方法是取一组基，扩充到全空间，然后分析。对于多个空间的情形，我们往往设出最小的空间，然后逐个扩大，这样通常是易于叙述的。

<!-- more -->
---

到了学习线代，基底仍然是非常好的化抽象为具象的手段。一个抽象的线性映射往往让人无从下手，设出基底，我们才能看到一个个的可感的对象。
通常的处理方法是取一组基，扩充到全空间，然后分析。对于多个空间的情形，我们往往设出最小的空间，然后逐个扩大，这样通常是易于叙述的。

* * *

## 准备：基扩充定理

设 $V$ 是一个有限维向量空间， $n = \dim(V)$ 。

若向量组 $\{\alpha_1, \alpha_2, \dots, \alpha_m\}$ 是 $V$ 中的一个线性无关组，则：

1\. 必有 $m \le n$ ； 2\. 若 $m < n$ ，则必存在 $n-m$ 个向量 $\alpha_{m+1}, \dots, \alpha_n \in V$ ，使得向量组 $\{\alpha_1, \dots, \alpha_m, \alpha_{m+1}, \dots, \alpha_n\}$ 构成 $V$ 的一个**基**。

**证明：** 设初始线性无关组为 $S_m = \{\alpha_1, \dots, \alpha_m\}$ 。

\- 如果 $S_m$ 已经能张成 $V$ （即 $\text{span}(S_m) = V$ ），那么根据定义， $S_m$ 就是 $V$ 的一个基，此时扩充过程结束。

\- 如果 $S_m$ 不能张成 $V$ ，则必然存在一个向量 $\beta \in V$ ，使得 $\beta \notin \text{span}(S_m)$ 。

从而我们可以把 $\beta$ 加入 $S_m$ 构成一个新的线性无关的向量组，下面只需证明这个过程可以通过有限步张成全空间，也就是只要证明一个 $n$ 维空间至多有 $n$ 个无关向量。 使用反证法，设 $V$ 有 $n+1$ 个无关向量，考虑



<p>
$$
\sum_{i=1}^{n} \lambda_i \alpha_i + \lambda_{n+1} \beta=0
$$
</p>



那么方程数多于未知数， $\lambda$ 有一组非零解，若 $\lambda_{n+1}=0$ ，则与 $S_m$ 线性无关矛盾，故 $\lambda_{n+1} \neq 0$ ，从而移项可知 $\beta$ 可以被 $S_m$ 表出，矛盾。 从而知道一个 $n$ 维空间至多有 $n$ 个线性无关的向量，故过程只需要有限步。 从而原命题成立。

* * *

## 扩充示例1：秩-零化度定理

考虑一个线性映射 $\mathcal{A} : V \to W$ ，我们总有：



<p>
$$
\dim(\text{Im}(\mathcal{A}))+\dim(\text{Ker}(\mathcal{A}))=\dim(V)
$$
</p>



**证明：** 我们取 $\text{Ker}(\mathcal{A})$ 的一组基 $\{\alpha_1, \alpha_2 ... \alpha_k\}$ ，将其扩充为 $V$ 的一组基 $\{\alpha_1, \alpha_2 ... \alpha_k, \alpha_{k+1}, \alpha_{n}\}$ ，接下来用 $\mathcal{A}$ 作用这组基，得到：



<p>
$$
\mathcal{A}(\alpha_1, \alpha_2 ... \alpha_k, \alpha_{k+1}, \alpha_{n})=(0,0...0, \mathcal{A}\alpha_{k+1}, \mathcal{A}\alpha_{n})
$$
</p>



我们要证明原定理，也只要证明后面的 $n-k$ 个向量能构成 $\mathcal{A}$ 的像空间的基。 首先， $\forall \beta \in V$ ，由于 $\{\alpha_1, \alpha_2 ... \alpha_k, \alpha_{k+1}, \alpha_{n}\}$ 是 $V$ 的基，我们有：



<p>
$$
\beta=\sum_{i=1}^n \lambda_i\alpha_i
$$
</p>



用 $\mathcal{A}$ 作用在两侧，得到：



<p>
$$
\mathcal{A}\beta=\sum_{i=k+1}^n \lambda_i\mathcal{A}\alpha_i
$$
</p>



也就是，对于 $\forall \mathcal{A}\beta \in V$ 其都可以被 $\mathcal{A}\alpha_{k+1},..., \mathcal{A}\alpha_{n}$ 表出，只需证 $\mathcal{A}\alpha_{k+1},..., \mathcal{A}\alpha_{n}$ 线性无关即可说明他们构成 $\text{Im}\mathcal{A}$ 的基，我们考虑：



<p>
$$
\sum_{i=k+1}^n \lambda_i\mathcal{A}\alpha_i=0
$$
</p>



利用线性，可以提出 $\mathcal{A}$ ：



<p>
$$
\sum_{i=k+1}^n \lambda_i\mathcal{A}\alpha_i=\mathcal{A}\sum_{i=k+1}^n \lambda_i\alpha_i=0
$$
</p>



这说明：



<p>
$$
\sum_{i=k+1}^n \lambda_i\alpha_i \in \text{Ker}(A)
$$
</p>



也就是说，这可以被 $\text{Ker}(A)$ 的基表出：



<p>
$$
\sum_{i=k+1}^n \lambda_i\alpha_i=\sum_{i=1}^k \lambda_i\alpha_i
$$
</p>



移项得到：



<p>
$$
\sum_{i=k+1}^n \lambda_i\alpha_i-\sum_{i=1}^k \lambda_i\alpha_i=0
$$
</p>



利用 $V$ 中基的线性无关性知，上式成立当且仅当 $\forall i, \lambda_i=0$ ，这正是 $\mathcal{A}\alpha_{k+1},..., \mathcal{A}\alpha_{n}$ 线性无关的等价条件。从而我们就完成了证明。

* * *

## 扩充示例2：矩阵乘积秩的维数定理证明

### 定理表述

设矩阵 $A$ 的列数等于矩阵 $B$ 的行数。记 $B$ 的列空间为 $V$ ， $A$ 的解空间（零空间）为 $W$ 。则有：



<p>
$$
\text{rank}(B) = \text{rank}(AB) + \dim(V \cap W)
$$
</p>



* * *

### 证明过程

### 1\. 构造基向量

将 $V \cap W$ 的一组基 $\alpha_1, \cdots, \alpha_r$ 扩充成 $B$ 的列空间 $V$ 的一组基：



<p>
$$
\alpha_1, \cdots, \alpha_r, \beta_1, \cdots, \beta_s
$$
</p>



显然，此时有：

* $\dim(V \cap W) = r$ * $\text{rank}(B) = \dim(V) = r + s$ * 我们目标是证明 $\text{rank}(AB) = s$ ### 2\. 确定 $AB$ 列空间的生成组

由于 $B$ 的列组与 $\alpha_1, \cdots, \alpha_r, \beta_1, \cdots, \beta_s$ 等价，根据矩阵乘法性质， $AB$ 的列组与 $A\alpha_1, \cdots, A\alpha_r, A\beta_1, \cdots, A\beta_s$ 等价。 又因为 $\alpha_i \in W$ （ $A$ 的解空间），故有 $A\alpha_1 = \cdots = A\alpha_r = \mathbf{0}$ 。 因此， $AB$ 的列空间可由剩余向量生成：



<p>
$$
\text{Range}(AB) = \text{span}\{ A\beta_1, \cdots, A\beta_s \}
$$
</p>



### 3\. 证明 $A\beta_1, \cdots, A\beta_s$ 线性无关

设有线性组合：



<p>
$$
k_1 A\beta_1 + \cdots + k_s A\beta_s = \mathbf{0}
$$
</p>



根据线性映射性质，可得：



<p>
$$
A(k_1 \beta_1 + \cdots + k_s \beta_s) = \mathbf{0}
$$
</p>



这说明向量 $\sum_{i=1}^s k_i \beta_i$ 既在 $A$ 的解空间 $W$ 中，又在 $B$ 的列空间 $V$ 中。 因此，它属于交集 $V \cap W$ ，可由其基向量 $\alpha_1, \cdots, \alpha_r$ 线性表示：



<p>
$$
k_1 \beta_1 + \cdots + k_s \beta_s = l_1 \alpha_1 + \cdots + l_r \alpha_r
$$
</p>



移项得：



<p>
$$
k_1 \beta_1 + \cdots + k_s \beta_s - l_1 \alpha_1 - \cdots - l_r \alpha_r = \mathbf{0}
$$
</p>



注意到 $\alpha_1, \cdots, \alpha_r, \beta_1, \cdots, \beta_s$ 是 $V$ 的基（线性无关），故其系数必全为 $0$ ：



<p>
$$
k_1 = \cdots = k_s = 0
$$
</p>



由此得 $A\beta_1, \cdots, A\beta_s$ 线性无关。

### 4\. 结论

既然 $A\beta_1, \cdots, A\beta_s$ 线性无关且生成 $AB$ 的列空间，则它们构成 $AB$ 列空间的基。故：



<p>
$$
\text{rank}(AB) = s
$$
</p>



代入之前的等式：



<p>
$$
\text{rank}(B) = r + s = \dim(V \cap W) + \text{rank}(AB)
$$
</p>



移项得：



<p>
$$
\text{rank}(AB) = \text{rank}(B) - \dim(V \cap W)
$$
</p>



* * *

## 扩充示例3：和空间的维度公式



<p>
$$
\dim(V)+\dim(W)=\dim(V\cap W)+\dim(V+ W)
$$
</p>



其中 $V + W = \{v + w \mid v \in V, w \in W\}$ 是包含 $V$ 和 $W$ 的最小向量空间。

### 证明步骤

1. **设定交集的基** ：
设 $\dim(V \cap W) = k$ ，取其基为 ${u_1, \dots, u_k}$ 。

2. **扩张基空间** ：

* 扩张为 $V$ 的基： ${u_1, \dots, u_k, v_1, \dots, v_m}$ ，则 $\dim(V) = k + m$ 。
* 扩张为 $W$ 的基： ${u_1, \dots, u_k, w_1, \dots, w_n}$ ，则 $\dim(W) = k + n$ 。
3. **确定和空间的基** ：
证明集合 $B = {u_1, \dots, u_k, v_1, \dots, v_m, w_1, \dots, w_n}$ 是 $V+W$ 的基。

* **生成性** ：显然 $V+W$ 中的任意元素都能被 $B$ 线性表示。
* **线性无关性** ：设



<p>
$$
\sum a_i u_i + \sum b_j v_j + \sum c_l w_l = 0
$$
</p>



变形得： $\sum c_l w_l = -(\sum a_i u_i + \sum b_j v_j)$ 。 等式左边属于 $W$ ，右边属于 $V$ ，因此该向量属于 $V \cap W$ 。 这意味着左边的 $\sum c_l w_l$ 必须能被 $\{u_1, \dots, u_k\}$ 线性表示。由于 $\{u_i, w_l\}$ 是 $W$ 的基，是线性无关的，所以所有的 $c_l$ 必须为 $0$ 。以此类推，所有系数均为 $0$ 。

4. **代数等式验证** ：



<p>
$$
\begin{aligned} \dim(V) + \dim(W) &= (k + m) + (k + n) \ &= k + (k + m + n) \ &= \dim(V \cap W) + \dim(V + W) \end{aligned}
$$
</p>



* * *

## 扩充示例4：特征值代数重数 $\ge$ 几何重数

我们设 $\lambda$ 是矩阵 $A$ 的一个特征值，代数重数即 $\det(A-\lambda I)=0$ 中 $\lambda$ 的重根数，几何重数即满足 $(A-\lambda I)\alpha=0$ 的 $\alpha$ 个数。我们总有代数重数 $\ge$ 几何重数。

**证明：** 取出 $\lambda$ 对应的特征子空间的一组基, $\alpha_1,...,\alpha_k$ ， $k$ 即几何重数，把基扩充到全空间，得到 $\alpha_1,...,\alpha_n$ 。我们用 $A$ 作用：



<p>
$$
A(\alpha_1,...,\alpha_n)=(\alpha_1,...,\alpha_n)

\begin{pmatrix} \lambda I_k & B \ O & C \end{pmatrix}
$$
</p>



从而 $A$ 相似于 $\begin{pmatrix} \lambda I_k & B \ O & C \end{pmatrix}$ ，从而他们特征多项式相同，考虑其特征多项式：



<p>
$$
\det

\begin{pmatrix} (\lambda-x) I_k & B \ O & C \end{pmatrix}
$$
</p>



展开即知至少有 $\lambda$ 的 $k$ 次方项，结合未知的 $C$ 即知，有代数重数 $\ge$ 几何重数。

* * *

## 换基与过渡矩阵

### 1\. 过渡矩阵的定义

设 $\alpha_1, \alpha_2, \dots, \alpha_n$ 与 $\beta_1, \beta_2, \dots, \beta_n$ 是线性空间 $V$ 的两组基。 若基 $\beta$ 可以由基 $\alpha$ 线性表示：



<p>
$$
\begin{cases} \beta_1 = b_{11}\alpha_1 + b_{12}\alpha_2 + \dots + b_{1n}\alpha_n \ \beta_2 = b_{21}\alpha_1 + b_{22}\alpha_2 + \dots + b_{2n}\alpha_n \ \quad \dots \quad \dots \ \beta_n = b_{n1}\alpha_1 + b_{n2}\alpha_2 + \dots + b_{nn}\alpha_n \end{cases}
$$
</p>



则从基 $\{\alpha_i\}$ 到基 $\{\beta_i\}$ 的**过渡矩阵** $B$ 定义为：



<p>
$$
(\beta_1 \dots \beta_n) = (\alpha_1 \dots \alpha_n) \underbrace{

\begin{bmatrix} b_{11} & b_{21} & \dots & b_{n1} \ b_{12} & b_{22} & \dots & b_{n2} \ \vdots & \vdots & & \vdots \ b_{1n} & b_{2n} & \dots & b_{nn} \end{bmatrix}

}_{B}
$$
</p>



> **注意**
> 过渡矩阵 $B$ 的第 $j$ 列是新基 $\beta_j$ 在旧基 $\alpha$ 下的坐标。

**双向转换关系** 如果从 $\alpha$ 到 $\beta$ 的过渡矩阵是 $B$ ，从 $\beta$ 到 $\alpha$ 的过渡矩阵是 $A$ ，则：

* $(\alpha_1 \dots \alpha_n) = (\beta_1 \dots \beta_n) A$ * 结合 $(\beta_1 \dots \beta_n) = (\alpha_1 \dots \alpha_n) B$ * 可得： $(\alpha_1 \dots \alpha_n) = (\alpha_1 \dots \alpha_n) BA \implies BA = I_n$ * 因此：** $A = B^{-1}$ * * *

### 2\. 坐标变换公式

**定理：** 若向量 $\alpha$ 在基 $\alpha_1, \dots, \alpha_n$ 下的坐标为 $X$ ，从旧基到新基 $\beta_1, \dots, \beta_n$ 的过渡矩阵为 $B$ ，则 $\alpha$ 在新基下的坐标为 $B^{-1}X$ 。

**推导过程：**



<p>
$$
\begin{aligned} \alpha &= [\alpha_1 \dots \alpha_n] X \ &= ([\beta_1 \dots \beta_n] B^{-1}) X \ &= [\beta_1 \dots \beta_n] (B^{-1}X) \end{aligned}
$$
</p>



* * *

### 3\. 基的判定定理

**定理：** 设 $\alpha_1, \dots, \alpha_n$ 是线性空间 $V$ 的一组基， $B$ 是 $n$ 阶方阵。 令：



<p>
$$
(\beta_1 \dots \beta_n) = (\alpha_1 \dots \alpha_n) B
$$
</p>



则：

> **结论** > $\beta_1, \dots, \beta_n$ 是 $V$ 的基 $ \iff



<p>
$$
B $ 可逆 充分性：右乘 $ B^{-1} $ 即知，必要性：从而向量组 $ \beta_i $ 表出基 $ \alpha_i $ ，利用1中双向转换关系即知。 * * * ## 线性映射、矩阵与基 ### 研究一个线性映射，只要看基的像 考虑线性映射 $ \mathcal{A} : V \to M $ ，我们要考虑一个任意的 $ \beta \in V$ 的映射结果，可以先用基底表示：
$$
</p>



\beta = \sum \lambda_i\alpha_i



<p>
$$
然后在两边用 $ \mathcal{A}$ 作用，得到：
$$
</p>



\mathcal{A}\beta=\sum\lambda_i(\mathcal{A}\alpha_i)



<p>
$$
从而我们只要知道基的像，也就可以确定任意 $ \beta \in V$ 的像。

### 线性映射可以用矩阵表示

在线性空间 $V $ 中，同一个线性映射 $ \mathcal{A}$ ，在不同的基下会对应不同的矩阵。

设 $\alpha_1, \dots, \alpha_n $ 是 $ V $ 的一组基。线性映射 $ \mathcal{A} $ 对基向量的作用可以表示为：
$$
</p>



\mathcal{A}(\alpha_j) = \sum_{i=1}^n a_{ij}\alpha_i



<p>
$$
写成矩阵形式：
$$
</p>



\mathcal{A}(\alpha_1, \dots, \alpha_n) = (\alpha_1, \dots, \alpha_n) A



<p>
$$
这里的 $ A $ 就是映射 $ \mathcal{A} $ 在基 $ \{\alpha_i\} $ 下的矩阵。 矩阵 $ A $ 的第 $ j $ 列，就是第 $ j $ 个基向量的像 $ \mathcal{A}(\alpha_j)$ 在原基底下的坐标。 线性映射之间的“逻辑运算”可以完美转化为矩阵之间的“代数运算”。这使得复杂的几何研究可以变成简单的算术：

设 $\mathcal{A}, \mathcal{B} $ 是 $ V $ 上的线性变换，在基 $ \alpha $ 下的矩阵分别为 $ A, B$ ，则：

* **线性组合：** $k\mathcal{A} + m\mathcal{B} $ 对应的矩阵是 $ kA + mB$ 。
* **复合映射：** $\mathcal{A} \circ \mathcal{B} $ （先做 $ \mathcal{B} $ 再做 $ \mathcal{A} $ ）对应的矩阵是 ** $ AB$ ** 。
* _注意：_ 矩阵乘法的顺序与映射复合的顺序一致，这正是矩阵乘法定义得如此“奇怪”的根本原因。
* **逆映射：** 若 $\mathcal{A} $ 可逆，其逆映射 $ \mathcal{A}^{-1} $ 对应的矩阵是 $ A^{-1}$ 。

### 相似矩阵的由来：换基公式

**定理：**设线性映射 $\mathcal{A} $ 在基 $ \{\alpha_i\} $ 下的矩阵为 $ A $ ，在基 $ \{\beta_i\} $ 下的矩阵为 $ A' $ 。如果从 $ \{\alpha_i\} $ 到 $ \{\beta_i\} $ 的过渡矩阵是 $ B $ ，那么：
$$
</p>



A' = B^{-1}AB



<p>
$$
想象你要计算 $ \mathcal{A} $ 对一个向量的作用，但你手里只有新基下的坐标 $ X'$ ：

1. ** $B X’ $ ** ：先将新坐标还原回旧基坐标（因为 $ A$ 只认旧基）。
2. ** $ A (B X’)$ ** ：在旧基下执行线性映射的操作。
3. ** $ B^{-1} (A B X’)$ ** ：将操作后的结果重新转换回新基下的坐标。

这就是为什么**矩阵相似（Similarity）** 的定义是 $A' = P^{-1}AP $ 。所谓相似矩阵，其实就是**同一个线性映射在不同基下的不同“化身”**。 既然同一映射在不同基下矩阵不同，我们自然会问：**能否找到一组基，使得矩阵 $ A'$ 尽可能简单？**

* **对角化：** 如果能找到一组基，使得 $ A’$ 是对角矩阵，那么这组基就是**特征向量** 基。
* **若尔当形（Jordan Form）：** 如果不能对角化，这组基就是广义特征向量基。

同时，在连续函数方面，我们同样可以选取漂亮的基。

### 傅里叶多项式、勒让德多项式与切比雪夫多项式

我们定义对于函数的内积：
$$
</p>



(f(x),g(x))=\int_{-1}^1 f(x)g(x)dx



<p>
$$
那么我们同样可以进行类似向量的操作，只不过现在是无穷维向量（定义域内有无穷多值），于是我们一个自然的想法是能不能用 $ 1,x,x^2...x^n.. $ 来作为一组基，但实际上这个基对应于 $ Hilbert$ 矩阵，并不是一个好矩阵。如同对向量那样，如果我们选取正交基，是非常美妙的，对应的系数只要做内积就可以得到。

#### 傅里叶多项式

对于周期函数，我们便可以选取 $ sinx, cosx, sin2x, cos2x… $ 作为基，可以验证这是一组正交基，那么便可以做投影：
$$
</p>



f(x)=c_{1}sinx+c_{2}cosx+c_{3}sin2x+c_4cos2x+...



<p>
$$
我们要求解系数，只需要两边做内积，例如：
$$
</p>



c_1=\frac{\int_{-1}^1f(x)\cdot sinxdx}{\int_{-1}^1sinx \cdot sinxdx}



<p>
$$
这样就求出了对应的系数，还是很方便的。

#### 勒让德多项式

如果我们想要正交基，我们通常从已有的基底做施密特正交化，我们在函数这里同样这么干：

##### 1\. 准备工作

* **定义区间** ：通常选取 $ [-1, 1]$ （在这个区间上得到的称为标准勒让德多项式）。

* **定义内积** ： $ \langle f, g \rangle = \int_{-1}^{1} f(x)g(x) dx$ 。

* **原始基向量** ： $ v_0 = 1, v_1 = x, v_2 = x^2, \dots$ * * *

##### 2\. 施密特正交化步骤

###### 第一步：确定第一个基 $P_0 $ 直接取 $ P_0(x) = v_0 = 1$ 。

###### 第二步：构造 $P_1 $ 我们需要从 $ v_1 = x $ 中减去它在 $ P_0 $ 方向上的投影：
$$
</p>



P_1(x) = x - \frac{\langle x, P_0 \rangle}{\langle P_0, P_0 \rangle} P_0



<p>
$$
* 计算内积： $ \langle x, 1 \rangle = \int_{-1}^{1} x dx = 0$ （奇函数在对称区间积分为 0）。

* 结论：** $ P_1(x) = x$ **。

###### 第三步：构造 $P_2 $ 我们需要从 $ v_2 = x^2 $ 中减去它在 $ P_0 $ 和 $ P_1 $ 方向上的投影：
$$
</p>



P_2(x) = x^2 - \frac{\langle x^2, P_0 \rangle}{\langle P_0, P_0 \rangle} P_0 - \frac{\langle x^2, P_1 \rangle}{\langle P_1, P_1 \rangle} P_1



<p>
$$
1. $ \langle x^2, P_0 \rangle = \int_{-1}^{1} x^2 \cdot 1 dx = \left[ \frac{1}{3}x^3 \right]_{-1}^{1} = \frac{2}{3} $ 2. $ \langle P_0, P_0 \rangle = \int_{-1}^{1} 1 \cdot 1 dx = 2 $ 3. $ \langle x^2, P_1 \rangle = \int_{-1}^{1} x^2 \cdot x dx = 0$ （奇函数积分为 0）

4. 代入公式： $ P_2(x) = x^2 - \frac{2/3}{2}(1) - 0 = \mathbf{x^2 - \frac{1}{3}}$ * * *

##### 3\. 归一化与标准形式

数学家为了方便（让 $ P_n(1) = 1$ ），通常会对结果进行缩放。

* 对于 $P_2(x) = x^2 - \frac{1}{3} $ ，乘以 $ \frac{3}{2} $ 得到： $ \mathbf{P_2(x) = \frac{1}{2}(3x^2 - 1)}$ 。

以此类推，你会得到：

* $P_0(x) = 1 $ * $ P_1(x) = x $ * $ P_2(x) = \frac{1}{2}(3x^2 - 1) $ * $ P_3(x) = \frac{1}{2}(5x^3 - 3x)$ 这就得到了勒让德多项式，这时做投影就仍然只需要做内积就行，方便得多。

#### 切比雪夫多项式
$$
</p>



T_n(\cos \theta) = \cos(n\theta)



<p>
$$
简单来说，就是 $ n$ 倍角公式对应的多项式，由于三角函数的正交性，这同样是正交基：
$$
</p>



\int_{0}^{\pi} \cos(m\theta) \cos(n\theta) d\theta = 0 \quad (m \neq n) $$ 同时，切比雪夫在数值分析中优于勒让德，因为我们可以利用 $FFT$ 大幅优化计算速度。
